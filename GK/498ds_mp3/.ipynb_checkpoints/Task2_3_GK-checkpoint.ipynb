{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "\n",
    "# install pgmpy using\n",
    "# pip3 install pgmpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1'],[2],[0.85,0.15])\n",
    "f_2 = DiscreteFactor(['S1','E1'],[2,2],[0.1,0.2,0,0.5])\n",
    "\n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1','E1'])  ## Add random variables \n",
    "G.add_factors(f_1,f_2)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1',f_1),('S1',f_2),('E1',f_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.7727 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.2273 |\n",
      "+-------+-----------+\n"
     ]
    }
   ],
   "source": [
    "bp = BeliefPropagation(G)\n",
    "#https://pgmpy.org/_modules/pgmpy/inference/ExactInference.html\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "margin = bp.query(variables = ['S1'],show_progress= False)\n",
    "margin.normalize()\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State S1 = 0 (No Attack) maximises marginal probability of S1\n"
     ]
    }
   ],
   "source": [
    "print('State S1 = 0 (No Attack) maximises marginal probability of S1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence E1=1\n",
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.1700 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.0750 |\n",
      "+-------+-----------+\n"
     ]
    }
   ],
   "source": [
    "margin = bp.query(variables = ['S1'],evidence = {'E1':1},show_progress= False)\n",
    "print('Evidence E1=1')\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We see that when E1 = 1 (Scan observed), S1 = 0 (No Attack) is the most probable state.\n"
     ]
    }
   ],
   "source": [
    "print('We see that when E1 = 1 (Scan observed), S1 = 0 (No Attack) is the most probable state.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Task 2.2\n"
     ]
    }
   ],
   "source": [
    "print('For Task 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint Probability is given by $P(E1,S1)=\\frac{1}{Z}f(S1)g(E1,S1)$ <br>\n",
    "where, <br>\n",
    "\n",
    "$Z = \\sum_{S1} \\sum_{E1} f(S1)g(E1,S1)$<br>\n",
    "$Z = 0.85*(0.1+0.2) + 0.15*(0+0.5)$<br>\n",
    "$z = 0.33$<br>\n",
    "\n",
    "**To get P(S1) we marginalise E1**<br>\n",
    "for S1 = 0: <br>\n",
    "$P(S1=0) = 1/0.33 * 0.85 * (0.1+0.2) $ <br>\n",
    "**$P(S1=0) = 0.7727$**\n",
    "\n",
    "\n",
    "for S1 = 1: <br>\n",
    "$P(S1=0) = 1/0.33 * 0.15 * (0+0.5) $ <br>\n",
    "**$P(S1=0) = 0.2272$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Task 2.4\n"
     ]
    }
   ],
   "source": [
    "print('For Task 2.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Probability when E1 = 1 is observed** <br>\n",
    "\n",
    "$P(S1 = 0 | E1 = 1) = \\frac{P(S1 = 0, E1 = 1)}{P(E1=1)} $ <br>\n",
    "$P(S1 = 1 | E1 = 1) = \\frac{P(S1 = 1, E1 = 1)}{P(E1=1)} $ <br>\n",
    "\n",
    "P(S1 = 0, E1 = 1) = 0.2 x 0.85 = 0.170 <br>\n",
    "P(S1 = 1, E1 = 1) = 0.5 x 0.15 = 0.075 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ATTACK_EVENTS_MAP = {\n",
    "    'Scan':1,\n",
    "    'Login':2,\n",
    "    'Sensitive_URI':3,\n",
    "    'New_Kernel_Module':4,\n",
    "    'DNS_Tunneling':5\n",
    "}\n",
    "ATTACK_STATES_MAP = {\n",
    "    'benign': 1,\n",
    "    'discovery': 2,\n",
    "    'access': 3,\n",
    "    'lateral_movement': 4,\n",
    "    'privilege_escalation': 5,\n",
    "    'persistence': 6,\n",
    "    'defense_evasion': 7,\n",
    "    'collection': 8,\n",
    "    'exfiltration': 9,\n",
    "    'command_control': 10,\n",
    "    'execution': 11\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Factor Functions:\n",
      "defaultdict(<class 'collections.Counter'>, {'Sensitive_URI': Counter({'benign': 0.5533333333333333, 'privilege_escalation': 0.44666666666666666}), 'Scan': Counter({'benign': 0.936, 'discovery': 0.064}), 'New_Kernel_Module': Counter({'benign': 0.875, 'persistence': 0.125}), 'DNS_Tunneling': Counter({'exfiltration': 0.98, 'benign': 0.02}), 'Login': Counter({'benign': 1.0})})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter,defaultdict\n",
    "\n",
    "##  Set up DS\n",
    "attack_events = list(ATTACK_EVENTS_MAP.keys())\n",
    "attack_states = list(ATTACK_STATES_MAP.keys())\n",
    "\n",
    "severity_factors = defaultdict(Counter)\n",
    "\n",
    "## Loop through event reviews file\n",
    "event_review = open('Datasets/event_review.txt', 'r') \n",
    "Lines = event_review.readlines() \n",
    "for line in Lines: \n",
    "    x = list([i[0] for i in map(str.split, line[7:].strip().split('//[Latent Attack State]'))])\n",
    "    severity_factors[x[0]][x[1]] +=1\n",
    "    \n",
    "# print(severity_factors)  \n",
    "\n",
    "## normalize the prob distribution\n",
    "for k in severity_factors.keys():\n",
    "    count = sum(severity_factors[k].values())\n",
    "    for i in severity_factors[k].keys():\n",
    "        severity_factors[k][i] /= count\n",
    "print('Severity Factor Functions:')\n",
    "print(severity_factors) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common continuous frequent sequence is \n",
      "[(('Scan', 'Sensitive_URI', 'New_Kernel_Module'), 200)]\n",
      "\n",
      "Most common continuous repetitive frequent sequence is \n",
      "[(('Sensitive_URI', 'Sensitive_URI', 'Sensitive_URI'), 186)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def sliding_window(seq, n=3):\n",
    "    \"credits: https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\"\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "\n",
    "##  Set up DS\n",
    "commonality_factors = Counter()\n",
    "repetitive_factors = Counter()\n",
    "\n",
    "## Loop through attack sequences file\n",
    "\n",
    "attack_sequences = open('Datasets/attack_sequences.txt', 'r') \n",
    "Lines = attack_sequences.readlines() \n",
    "for line in Lines:\n",
    "    line = line.strip().split(' ')\n",
    "#     print(line)\n",
    "    for window in sliding_window(line,n = 3):\n",
    "        if len(window) == 3:\n",
    "            if len(set(window)) > 1:\n",
    "                commonality_factors[tuple(window)] += 1\n",
    "            else:\n",
    "                repetitive_factors[tuple(window)] +=1\n",
    "    \n",
    "print('Most common continuous frequent sequence is ')\n",
    "print(commonality_factors.most_common(1))\n",
    "print('\\nMost common continuous repetitive frequent sequence is ')\n",
    "print(repetitive_factors.most_common(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2  You will have to submit the graph you draw through Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint 1.5 submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-620fe2175bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#   TODO: Define factor functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m###############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscreteFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mf_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscreteFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'values'"
     ]
    }
   ],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['e1','s1'],[1,11])\n",
    "f_2 = DiscreteFactor()\n",
    "...\n",
    "f_9 = DiscreteFactor()\n",
    "\n",
    "r = DiscreteFactor()\n",
    "c = DiscreteFactor() \n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from()  ## Add random variables \n",
    "G.add_factors()     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from()\n",
    "\n",
    "###############################\n",
    "#   TODO: Do the inference\n",
    "###############################\n",
    "bp = BeliefPropagation(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. At every time point, provide the marginal probability of each state (Since we have 9 time points and 11 possible states, you should provide 99 probability values here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. At every time point, provide the most probable state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate the earliest stage in which your model should recommend stopping the attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Judge whether the most probable states for $s_1-s_6,s_8,s_9$ remain the same as Task3.2\n",
    "#### b. State the reason for your judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Draw an HMM model for the attack scenario given the provided states and events.\n",
    "#### b. What parameters are needed for this HMM model to work?\n",
    "#### c. Give an example of an advantage of the FG over the HMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
