{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1'],[2],[0.85, 0.15]) #This is the prior 'f'\n",
    "f_2 = DiscreteFactor(['S1','E1'], [2,2], [0.1, 0.2, 0.0, 0.5])\n",
    "\n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1','E1'])  ## Add random variables \n",
    "G.add_factors(f_1, f_2)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1',f_1), ('S1',f_2), ('E1',f_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 & 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.2550 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.0750 |\n",
      "+-------+-----------+\n"
     ]
    }
   ],
   "source": [
    "bp = BeliefPropagation(G)\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "margin = bp.query(variables = ['S1'], show_progress = False)\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S_1$ = 0 (no attack) maximizes P($S_1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4 & 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.1700 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.0750 |\n",
      "+-------+-----------+\n"
     ]
    }
   ],
   "source": [
    "margin = bp.query(variables = ['S1'], evidence = {'E1':1}, show_progress = False)\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S_1$ = 0 (no attack) is the most probable on seeing $E_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 2.2:\n",
    "\n",
    "$$ P(S_1) \\propto \\displaystyle\\sum_{E1}  f(S_1) g(S_1,E_1) $$\n",
    "\n",
    "$$ P(S_1) \\propto f(S_1) g(S_1, E_1 = 0) + f(S_1) g(S_1, E_1 = 1) $$\n",
    "\n",
    "$$ P(S_1) \\propto \\begin{bmatrix} 0.85 \\\\ 0.15 \\end{bmatrix} \\begin{bmatrix}  0.1&+&0.2 \\\\ 0&+&0.5 \\end{bmatrix} $$\n",
    "\n",
    "$$ P(S_1) \\propto \\begin{bmatrix} 0.255 (S1 = 0) \\\\ 0.075 (S1 = 1) \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 2.3:\n",
    "\n",
    "$$ P(S_1 | E_1 = 1) \\propto  f(S_1) g(S_1,E_1 = 1) $$\n",
    "\n",
    "$$ P(S_1) \\propto f(S_1) g(S_1, E_1 = 1) $$\n",
    "\n",
    "$$ P(S_1) \\propto \\begin{bmatrix} 0.85 \\\\ 0.15 \\end{bmatrix} \\begin{bmatrix} 0.2 \\\\ 0.5 \\end{bmatrix} $$\n",
    "\n",
    "$$ P(S_1) \\propto \\begin{bmatrix} 0.170 \\\\ 0.075 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand calculations match what we get from the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_EVENTS_MAP = {\n",
    "    'Scan':1,\n",
    "    'Login':2,\n",
    "    'Sensitive_URI':3,\n",
    "    'New_Kernel_Module':4,\n",
    "    'DNS_Tunneling':5\n",
    "}\n",
    "ATTACK_STATES_MAP = {\n",
    "    'benign': 1,\n",
    "    'discovery': 2,\n",
    "    'access': 3,\n",
    "    'lateral_movement': 4,\n",
    "    'privilege_escalation': 5,\n",
    "    'persistence': 6,\n",
    "    'defense_evasion': 7,\n",
    "    'collection': 8,\n",
    "    'exfiltration': 9,\n",
    "    'command_control': 10,\n",
    "    'execution': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: [0.5533333333333333, 0, 0, 0, 0.44666666666666666, 0, 0, 0, 0, 0, 0],\n",
       " 1: [0.936, 0.064, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 4: [0.875, 0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0],\n",
       " 5: [0.02, 0, 0, 0, 0, 0, 0, 0, 0.98, 0, 0],\n",
       " 2: [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_review = open('event_review.txt', 'r') \n",
    "Lines = event_review.readlines()\n",
    "df = pd.DataFrame(index = range(len(Lines)), columns = ['Event', 'Latent Attack State'])\n",
    "i = 0\n",
    "for string in Lines:\n",
    "    df.loc[i,'Event'] = (string.split(' ')[0]).split(']')[1]\n",
    "    df.loc[i,'Latent Attack State'] = ((string.split(' ')[-1]).split('\\n')[0]).split(']')[-1]\n",
    "    if string.split(' ')[-1] == '\\n':\n",
    "        df.loc[i,'Latent Attack State'] = 'exfiltration'\n",
    "    i+=1\n",
    "\n",
    "df = df.replace({\"Event\":ATTACK_EVENTS_MAP, \"Latent Attack State\":ATTACK_STATES_MAP})\n",
    "\n",
    "f_dict = {}\n",
    "for event_ in df['Event'].unique():\n",
    "    templist = 11*[0]\n",
    "    newdf = df[df['Event'] == event_]\n",
    "    for i in newdf['Latent Attack State'].unique():\n",
    "        templist[i-1] = newdf['Latent Attack State'].value_counts()[i] / len(newdf)\n",
    "    f_dict[event_] = templist\n",
    "f_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.936, 0.064, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0.5533333333333333, 0, 0, 0, 0.44666666666666666, 0, 0, 0, 0, 0, 0],\n",
       " [0.5533333333333333, 0, 0, 0, 0.44666666666666666, 0, 0, 0, 0, 0, 0],\n",
       " [0.5533333333333333, 0, 0, 0, 0.44666666666666666, 0, 0, 0, 0, 0, 0],\n",
       " [0.875, 0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0],\n",
       " [0.02, 0, 0, 0, 0, 0, 0, 0, 0.98, 0, 0],\n",
       " [0.02, 0, 0, 0, 0, 0, 0, 0, 0.98, 0, 0],\n",
       " [0.02, 0, 0, 0, 0, 0, 0, 0, 0.98, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = [1,2,3,3,3,4,5,5,5] #e1 to e9 as given in the problem\n",
    "f = [] #A list of lists, each row is the fi for ei\n",
    "for event in events:\n",
    "    f.append(f_dict[event])\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the requried f1 to f9 (factor functions for the observed events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function was taken from stackoverflow: \n",
    "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
    "'''\n",
    "from itertools import islice\n",
    "\n",
    "def window(seq, n=3):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common event sequence: ('Scan', 'Sensitive_URI', 'New_Kernel_Module')\n",
      "Most common repeated sequence: ('Sensitive_URI', 'Sensitive_URI', 'Sensitive_URI')\n",
      "\n",
      "\n",
      "c: [0, 0, 0, 0, 0, 0.9306930693069307, 0, 0, 0, 0, 0]\n",
      "r: [0, 0, 0, 0, 0.7425742574257426, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "c_counter, r_counter = Counter(), Counter()\n",
    "\n",
    "attack_sequences = open('attack_sequences.txt', 'r') \n",
    "Lines = attack_sequences.readlines() \n",
    "for line in Lines:\n",
    "    l = line.strip().split(' ')\n",
    "    for sequence in window(l,3):\n",
    "        if len(set(sequence)) == 1:\n",
    "            r_counter[sequence] +=1\n",
    "        else:\n",
    "            c_counter[sequence] +=1\n",
    "\n",
    "c_sequence = c_counter.most_common(1)[0][0]\n",
    "r_sequence = r_counter.most_common(1)[0][0]\n",
    "print(\"Most common event sequence: {}\".format(c_sequence))\n",
    "print(\"Most common repeated sequence: {}\".format(r_sequence))\n",
    "\n",
    "#for probabilities:\n",
    "c_count_probability, r_count_probability = [], []\n",
    "\n",
    "for line in Lines:\n",
    "    l = line.strip().split(' ')\n",
    "    c, r = False, False\n",
    "    for sequence in window(l,3):\n",
    "        if sequence == c_sequence:\n",
    "            c = True\n",
    "        if sequence == r_sequence:\n",
    "            r = True\n",
    "    c_count_probability.append(c)\n",
    "    r_count_probability.append(r)\n",
    "\n",
    "cp = sum(c_count_probability)/len(c_count_probability)\n",
    "rp = sum(r_count_probability)/len(r_count_probability)\n",
    "#print(\"C sequence probability = {}\".format(cp))\n",
    "#print(\"R sequence probability = {}\".format(rp))\n",
    "\n",
    "#Since c accounts for the persistance state and r for the privilege escalation, we directly write the 11d vectors:\n",
    "c_factor_function, r_factor_function = 11*[0], 11*[0]\n",
    "c_factor_function[5] = cp\n",
    "r_factor_function[4] = rp\n",
    "print('\\n')\n",
    "print(\"c: {}\".format(c_factor_function))\n",
    "print(\"r: {}\".format(r_factor_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2  You will have to submit the graph you draw through Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted in CP1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['s1','e1'], [11,1], f[0])\n",
    "f_2 = DiscreteFactor(['s2','e2'], [11,1], f[1])\n",
    "f_3 = DiscreteFactor(['s3','e3'], [11,1], f[2])\n",
    "f_4 = DiscreteFactor(['s4','e4'], [11,1], f[3])\n",
    "f_5 = DiscreteFactor(['s5','e5'], [11,1], f[4])\n",
    "f_6 = DiscreteFactor(['s6','e6'], [11,1], f[5])\n",
    "f_7 = DiscreteFactor(['s7','e7'], [11,1], f[6])\n",
    "f_8 = DiscreteFactor(['s8','e8'], [11,1], f[7])\n",
    "f_9 = DiscreteFactor(['s9','e9'], [11,1], f[8])\n",
    "\n",
    "r = DiscreteFactor(['s5','e3','e4','e5'], [11,1,1,1], r_factor_function)\n",
    "c = DiscreteFactor(['s6','e1','e3','e6'], [11,1,1,1], c_factor_function) \n",
    "\n",
    "\n",
    "'''\n",
    "Ideally the graph should be analyzed in the way given in this comment. But pgmpy does not consider the entire graph\n",
    "together due to disconnected nodes, thus, we analyze individual sections of the graph.\n",
    "\n",
    "See the graph image provided with CP1.5 for more clarity.\n",
    "\n",
    "G.add_nodes_from(['s'+str(i+1) for i in range(9)] + ['e'+str(i+1) for i in range(9)])  ## Add random variables \n",
    "G.add_factors(f_1,f_2,f_3,f_4,f_5,f_6,f_7,f_8,f_9,r,c)     ## Add factor functions\n",
    "\n",
    "G.add_edges_from([('s1',f_1), ('e1', f_1),\n",
    "                  ('s2',f_2), ('e2', f_2),\n",
    "                  ('s3',f_3), ('e3', f_3),\n",
    "                  ('s4',f_4), ('e4', f_4),\n",
    "                  ('s5',f_5), ('e5', f_5),\n",
    "                  ('s6',f_6), ('e6', f_6),\n",
    "                  ('s7',f_7), ('e7', f_7),\n",
    "                  ('s8',f_8), ('e8', f_8),\n",
    "                  ('s9',f_9), ('e9', f_9),\n",
    "                  ('s5',r), ('e3', r), ('e4', r), ('e5', r),\n",
    "                  ('s6',c), ('e1', c), ('e3', c), ('e6', c)])\n",
    "'''\n",
    "\n",
    "marginals = 9*[0]\n",
    "\n",
    "#First let's analyze all independent nodes:\n",
    "independent_nodes = [2, 7, 8, 9]\n",
    "\n",
    "for node in independent_nodes:\n",
    "    G = FactorGraph()\n",
    "    G.add_nodes_from(['s'+str(node), 'e'+str(node)])\n",
    "    factor_function = DiscreteFactor(['s'+str(node), 'e'+str(node)], [11,1], f[node - 1])\n",
    "    G.add_factors(factor_function)\n",
    "    G.add_edges_from([('s'+str(node), factor_function), ('e'+str(node), factor_function)])\n",
    "    marginals[node - 1] =  BeliefPropagation(G).query(variables = ['s'+str(node)], show_progress = False)\n",
    "\n",
    "    \n",
    "#Now we analyze the other section of the graph, which has connected nodes s1, s3, s4, s5, s6\n",
    "G = FactorGraph()\n",
    "dependent_nodes = [1,3,4,5,6]\n",
    "\n",
    "G.add_nodes_from(['s'+str(i) for i in dependent_nodes] + ['e'+str(i) for i in dependent_nodes])  ## Add random variables \n",
    "G.add_factors(f_1,f_3,f_4,f_5,f_6,r,c)\n",
    "G.add_edges_from([('s1',f_1), ('e1', f_1),\n",
    "                  ('s3',f_3), ('e3', f_3),\n",
    "                  ('s4',f_4), ('e4', f_4),\n",
    "                  ('s5',f_5), ('e5', f_5),\n",
    "                  ('s6',f_6), ('e6', f_6),\n",
    "                  ('s5',r), ('e3', r), ('e4', r), ('e5', r),\n",
    "                  ('s6',c), ('e1', c), ('e3', c), ('e6', c)])\n",
    "\n",
    "bp = BeliefPropagation(G)\n",
    "for node in dependent_nodes:\n",
    "    marginals[node - 1] = bp.query(variables = ['s'+str(node)], show_progress = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. At every time point, provide the marginal probability of each state (Since we have 9 time points and 11 possible states, you should provide 99 probability values here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "| s1     |   phi(s1) |\n",
      "+========+===========+\n",
      "| s1(0)  |    0.9360 |\n",
      "+--------+-----------+\n",
      "| s1(1)  |    0.0640 |\n",
      "+--------+-----------+\n",
      "| s1(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s1(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s2     |   phi(s2) |\n",
      "+========+===========+\n",
      "| s2(0)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| s2(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s2(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s3     |   phi(s3) |\n",
      "+========+===========+\n",
      "| s3(0)  |    0.5533 |\n",
      "+--------+-----------+\n",
      "| s3(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(4)  |    0.4467 |\n",
      "+--------+-----------+\n",
      "| s3(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s3(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s4     |   phi(s4) |\n",
      "+========+===========+\n",
      "| s4(0)  |    0.5533 |\n",
      "+--------+-----------+\n",
      "| s4(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(4)  |    0.4467 |\n",
      "+--------+-----------+\n",
      "| s4(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s4(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s5     |   phi(s5) |\n",
      "+========+===========+\n",
      "| s5(0)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(4)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| s5(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s5(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s6     |   phi(s6) |\n",
      "+========+===========+\n",
      "| s6(0)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(5)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| s6(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s6(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s7     |   phi(s7) |\n",
      "+========+===========+\n",
      "| s7(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| s7(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| s7(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s7(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s8     |   phi(s8) |\n",
      "+========+===========+\n",
      "| s8(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| s8(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| s8(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s8(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n",
      "+--------+-----------+\n",
      "| s9     |   phi(s9) |\n",
      "+========+===========+\n",
      "| s9(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| s9(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| s9(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| s9(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for marginal in marginals:\n",
    "    marginal.normalize()\n",
    "    print(marginal)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. At every time point, provide the most probable state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most probable states at each time point are:\n",
    "\n",
    "t = 1: benign\n",
    "\n",
    "t = 2: benign\n",
    "\n",
    "t = 3: benign\n",
    "\n",
    "t = 4: benign\n",
    "\n",
    "t = 5: privilege escalation\n",
    "\n",
    "t = 6: persistence\n",
    "\n",
    "t = 7: exfiltration\n",
    "\n",
    "t = 8: exfiltration\n",
    "\n",
    "t = 9: exfiltration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO-OP', 'NO-OP', 'NO-OP', 'NO-OP', 'MONITOR', 'MONITOR', 'STOP', 'STOP', 'STOP']\n"
     ]
    }
   ],
   "source": [
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}\n",
    "\n",
    "hidden_states = ['benign', 'benign', 'benign', 'benign', 'privilege_escalation', 'persistence','exfiltration', 'exfiltration', 'exfiltration']\n",
    "hidden_states_mapped = [ATTACK_STATES_MAP[state] for state in hidden_states]\n",
    "\n",
    "actions = []\n",
    "temp = np.argmax(np.array(list(ACTIONS.values())), axis = 0)\n",
    "for i in hidden_states_mapped:\n",
    "    actions.append(list(ACTIONS.keys())[temp[i-1]])\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate the earliest stage in which your model should recommend stopping the attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earliest stage in which 'STOP' is recommended is S7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Judge whether the most probable states for $s_1-s_6,s_8,s_9$ remain the same as Task3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the new factor graph without s7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "f_1 = DiscreteFactor(['s1','e1'], [11,1], f[0])\n",
    "f_2 = DiscreteFactor(['s2','e2'], [11,1], f[1])\n",
    "f_3 = DiscreteFactor(['s3','e3'], [11,1], f[2])\n",
    "f_4 = DiscreteFactor(['s4','e4'], [11,1], f[3])\n",
    "f_5 = DiscreteFactor(['s5','e5'], [11,1], f[4])\n",
    "f_6 = DiscreteFactor(['s6','e6'], [11,1], f[5])\n",
    "#f_7 = DiscreteFactor(['s7','e7'], [11,1], f[6])\n",
    "f_8 = DiscreteFactor(['s8','e8'], [11,1], f[7])\n",
    "f_9 = DiscreteFactor(['s9','e9'], [11,1], f[8])\n",
    "\n",
    "r = DiscreteFactor(['s5','e3','e4','e5'], [11,1,1,1], r_factor_function)\n",
    "c = DiscreteFactor(['s6','e1','e3','e6'], [11,1,1,1], c_factor_function) \n",
    "\n",
    "\n",
    "marginals_without_7 = 9*[0]\n",
    "\n",
    "#First let's analyze all independent nodes:\n",
    "independent_nodes = [2, 8, 9]\n",
    "\n",
    "for node in independent_nodes:\n",
    "    G = FactorGraph()\n",
    "    G.add_nodes_from(['s'+str(node), 'e'+str(node)])\n",
    "    factor_function = DiscreteFactor(['s'+str(node), 'e'+str(node)], [11,1], f[node - 1])\n",
    "    G.add_factors(factor_function)\n",
    "    G.add_edges_from([('s'+str(node), factor_function), ('e'+str(node), factor_function)])\n",
    "    marginals_without_7[node - 1] =  BeliefPropagation(G).query(variables = ['s'+str(node)], show_progress = False)\n",
    "\n",
    "    \n",
    "#Now we analyze the other section of the graph, which has connected nodes s1, s3, s4, s5, s6\n",
    "G = FactorGraph()\n",
    "dependent_nodes = [1,3,4,5,6]\n",
    "\n",
    "G.add_nodes_from(['s'+str(i) for i in dependent_nodes] + ['e'+str(i) for i in dependent_nodes])  ## Add random variables \n",
    "G.add_factors(f_1,f_3,f_4,f_5,f_6,r,c)\n",
    "G.add_edges_from([('s1',f_1), ('e1', f_1),\n",
    "                  ('s3',f_3), ('e3', f_3),\n",
    "                  ('s4',f_4), ('e4', f_4),\n",
    "                  ('s5',f_5), ('e5', f_5),\n",
    "                  ('s6',f_6), ('e6', f_6),\n",
    "                  ('s5',r), ('e3', r), ('e4', r), ('e5', r),\n",
    "                  ('s6',c), ('e1', c), ('e3', c), ('e6', c)])\n",
    "\n",
    "bp = BeliefPropagation(G)\n",
    "for node in dependent_nodes:\n",
    "    marginals_without_7[node - 1] = bp.query(variables = ['s'+str(node)], show_progress = False)\n",
    "\n",
    "for i in range(9):\n",
    "    try:\n",
    "        marginals_without_7[i].normalize()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    print(marginals_without_7[i] == marginals[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The only False is at s7 because s7 doesn't exist in the new FG. All other marginals remain the same.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. State the reason for your judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Factor Graph drawing, we see that s7 - e7 is independent of all other nodes. It is not connected to any other state via any factor function, like r or c. Hence, the value of s7 (or any indepenedent state-event pair) does not affect the rest of the graph in the belief propagation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Draw an HMM model for the attack scenario given the provided states and events.\n",
    "\n",
    "Will be drawn in the final ppt.\n",
    "\n",
    "\n",
    "#### b. What parameters are needed for this HMM model to work?\n",
    "\n",
    "The state transition matrix, the observation matrix and the priors.\n",
    "\n",
    "\n",
    "#### c. Give an example of an advantage of the FG over the HMM model.\n",
    "\n",
    "The FG follows a more general approach and is not restricted by a Markov assumption like in HMMs. This allows us to include factor functions like 'r' and 'c' to include any number of relationships between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.0\n",
    "#### Is it possible to 100% detect this attack using only one event, e.g., ϵ1, of the six listed events? Briefly explain.\n",
    "No, it's not possible to detect this attack with 100% certainty using only one event. This is because each event has some probability of being associated with \"benign\" in the corresponding attack state, which corresponds to a legitimate user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1\n",
    "#### For each of the six listed events, give an example of a situation in which a false positive (i.e., mis-detecting a legitimate user as an attacker) could happen.\n",
    "**Scan**: The system admin is doing the scan instead of the attacker.\n",
    "\n",
    "**Login**: No false positives possible as the event maps to only one state (benign).\n",
    "\n",
    "**Sensitive URI**: Since the sensitive URI here indicates a URI pointing to an executable, false positive can be generated when a legitimate user tries to access any URI executable (not necessarily from the attacker-controlled server).\n",
    "\n",
    "**New Exe File**: Same as sensitive URI.\n",
    "\n",
    "**Homepage Overwritten with new link**: Legitimate user themselves overwrite the homepage with a new link, which does not necessarily come from the exe file donwloaded from the attacker's server.\n",
    "\n",
    "**Webserver Restarted**: Same as Homepage overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2\n",
    "#### Provide a visual representation of a factor graph that can model the attack described above.\n",
    "Included in the final ppt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3\n",
    "#### What variables and factor functions are common to the factor graph in Task 3 and your factor graph in 4.2?\n",
    "The events Scan, Login and Sensitive URI are common to both factor graphs. Moreover they also map to the same states in both FGs:\n",
    "\n",
    "Scan -> {benign, discovery}\n",
    "\n",
    "Login -> {benign}\n",
    "\n",
    "Sensitive URI -> {benign, privilege escalation}\n",
    "\n",
    "(this can be seen in the f_dict dictionary for our previous FG)\n",
    "\n",
    "Thus the severity factor functions corresponsing to these states can be common (assuming that the event sequences generated in event_review.txt are sufficiently general to both attack scenarios).\n",
    "\n",
    "The above analysis is for a general scenario. **For the particular attack sequence observed**, the set \\[Scan, Login, Sensitive URI, Sensitive URI, Sensitive URI\\] is common. Thus in the particular scenario, the severity factor functions f_1 through f_5 and the repeptitive factor function \"r\" are common to both FGs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
