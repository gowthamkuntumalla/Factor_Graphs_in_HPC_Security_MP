{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.inference import BeliefPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1'], [2,], [0.85, 0.15])\n",
    "f_2 = DiscreteFactor(['S1', 'E1'], [2,2], [[0.1, 0.2], [0, 0.5]])\n",
    "\n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1', 'E1'])  ## Add random variables \n",
    "G.add_factors(f_1, f_2)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1', f_1), ('S1', f_2), ('E1', f_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Marginal Probability of S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: E1: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 247.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.7727 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.2273 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bp = BeliefPropagation(G)\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "\n",
    "margin = bp.query(variables=['S1'])\n",
    "margin.normalize()\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Value of S1 that maximizes its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: E1: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S1': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.map_query(variables=['S1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most probable state for S1 is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: P(S1) when E1 = 1 is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.6939 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.3061 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "margin = bp.query(variables=['S1'], evidence = {'E1': 1})\n",
    "margin.normalize()\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5 Most probable state for S1 when E1=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S1': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.map_query(variables=['S1'], evidence = {'E1': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most probable state for S1 when E1 = 1 is: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare above results with hand calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_EVENTS_MAP = {\n",
    "    'Scan':1,\n",
    "    'Login':2,\n",
    "    'Sensitive_URI':3,\n",
    "    'New_Kernel_Module':4,\n",
    "    'DNS_Tunneling':5\n",
    "}\n",
    "ATTACK_STATES_MAP = {\n",
    "        'benign': 1,\n",
    "        'discovery': 2,\n",
    "    'access': 3,\n",
    "    'lateral_movement': 4,\n",
    "        'privilege_escalation': 5,\n",
    "        'persistence': 6,\n",
    "    'defense_evasion': 7,\n",
    "    'collection': 8,\n",
    "        'exfiltration': 9,\n",
    "    'command_control': 10,\n",
    "    'execution': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor function values are:\n",
      " [[468. 100. 166. 175.   2.]\n",
      " [ 32.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.]\n",
      " [  0.   0. 134.   0.   0.]\n",
      " [  0.   0.   0.  25.   0.]\n",
      " [  0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  98.]\n",
      " [  0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.]]\n",
      "\n",
      "Factor functions (in terms of probability):\n",
      " [[0.936      1.         0.55333333 0.875      0.02      ]\n",
      " [0.064      0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.44666667 0.         0.        ]\n",
      " [0.         0.         0.         0.125      0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.98      ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "event_review = open('data/event_review.txt', 'r') \n",
    "Lines = event_review.readlines() \n",
    "\n",
    "f = np.zeros([len(ATTACK_STATES_MAP), len(ATTACK_EVENTS_MAP)])\n",
    "\n",
    "for line in Lines:\n",
    "    for event, event_num in ATTACK_EVENTS_MAP.items():\n",
    "        if (event in line):\n",
    "            for state, state_num in ATTACK_STATES_MAP.items():\n",
    "                if (state in line):\n",
    "                    f[state_num-1, event_num-1] += 1\n",
    "print(\"Factor function values are:\\n\", f)   \n",
    "\n",
    "# Normalize the factor function by columns:\n",
    "for i in range(len(f.transpose())):\n",
    "    f.transpose()[i] = f.transpose()[i] / np.linalg.norm(f.transpose()[i], ord = 1)\n",
    "\n",
    "print(\"\\nFactor functions (in terms of probability):\\n\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of counts observed:\n",
      "\n",
      "1: Commonness\n",
      "             Number\n",
      "Combination        \n",
      "134             200\n",
      "212              15\n",
      "121              27\n",
      "215              22\n",
      "151              20\n",
      "...             ...\n",
      "511              11\n",
      "114              11\n",
      "525              14\n",
      "544              11\n",
      "244               8\n",
      "\n",
      "[125 rows x 1 columns]\n",
      "2: Repetiveness\n",
      "             Number\n",
      "Combination        \n",
      "333             186\n",
      "222               7\n",
      "111              25\n",
      "444              25\n",
      "555              15\n",
      "\n",
      "COMMONNESS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Common Event Sequence</th>\n",
       "      <th>Factor Function</th>\n",
       "      <th>Attack States</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Scan, Sensitive_URI, New_Kernel_Module]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0.071, 0, 0, 0, 0, 0]</td>\n",
       "      <td>persistence</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Most Common Event Sequence  \\\n",
       "0  [Scan, Sensitive_URI, New_Kernel_Module]   \n",
       "\n",
       "                         Factor Function Attack States  Probability  \n",
       "0  [0, 0, 0, 0, 0, 0.071, 0, 0, 0, 0, 0]   persistence        0.071  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REPETITIVENESS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Common Event Sequence</th>\n",
       "      <th>Factor Function</th>\n",
       "      <th>Attack States</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sensitive_URI, Sensitive_URI, Sensitive_URI]</td>\n",
       "      <td>[0, 0, 0, 0, 0.721, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>persistence</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Most Common Event Sequence  \\\n",
       "0  [Sensitive_URI, Sensitive_URI, Sensitive_URI]   \n",
       "\n",
       "                         Factor Function Attack States  Probability  \n",
       "0  [0, 0, 0, 0, 0.721, 0, 0, 0, 0, 0, 0]   persistence        0.721  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_sequences = open('data/attack_sequences.txt', 'r') \n",
    "Lines = attack_sequences.readlines() \n",
    "\n",
    "seq = [] # Stores the sequence of events executed in a particular attack sequence\n",
    "table = {} # Counts the factor functions\n",
    "table_rep = {} # Counts the factors for repetitive patterns\n",
    "\n",
    "for line in Lines: # Extract one attack sequence\n",
    "    line = line.split(\" \")\n",
    "    line.pop()\n",
    "    for key in line: # Extract event from attack sequence\n",
    "        #Converts the attack sequence to list with corresponding coded numbers for easier processing\n",
    "        seq.append(ATTACK_EVENTS_MAP[key]) \n",
    "        \n",
    "    i = 2\n",
    "    while i < len(seq):\n",
    "        # Sliding window implementation\n",
    "        a = str(seq[i-2])\n",
    "        b = str(seq[i-1])\n",
    "        c = str(seq[i]) \n",
    "        \n",
    "        # Repetitiveness check and increment counter for the sequence\n",
    "        if a == b and b ==  c:\n",
    "            try:\n",
    "                table_rep[a+b+c] += 1\n",
    "            except:\n",
    "                table_rep[a+b+c] = 1\n",
    "       \n",
    "        # Commonness: increment counter for the sequence\n",
    "        try:\n",
    "            table[a+b+c] += 1\n",
    "        except:\n",
    "            table[a+b+c] = 1\n",
    "        i += 1 \n",
    "    \n",
    "    seq = [] # reset the sequence for next attack\n",
    "\n",
    "print(\"The number of counts observed:\\n\")\n",
    "print(\"1: Commonness\")\n",
    " \n",
    "#Following snippet normalizes the number of counts in table and sorts them in desc order\n",
    "common = pd.DataFrame(list(table.items()), columns = ['Combination', 'Number'])\n",
    "print(common.set_index('Combination'))\n",
    "common['Number'] /= common['Number'].sum()\n",
    "common.sort_values(['Number'], ascending = False, inplace = True)\n",
    "\n",
    "print(\"2: Repetiveness\")\n",
    "#Following snippet normalizes the number of counts in table_rep and sorts them in desc order\n",
    "common_rep = pd.DataFrame(list(table_rep.items()), columns = ['Combination', 'Number'])\n",
    "print(common_rep.set_index('Combination'))\n",
    "common_rep['Number'] /= common_rep['Number'].sum()\n",
    "common_rep.sort_values(['Number'], ascending = False, inplace = True)\n",
    "\n",
    "most_common_seq = [] # Most common seq overall\n",
    "most_common_rep_seq = [] # Most common repetitive seq\n",
    "\n",
    "# Just converts the number encoding back to string type description of events: For eg: \"1\" gets converted to \"Scan\"\n",
    "for x in common['Combination'].loc[0]:\n",
    "    for key, value in ATTACK_EVENTS_MAP.items():\n",
    "        if value == int(x):\n",
    "            most_common_seq.append(key)\n",
    "\n",
    "for x in common_rep['Combination'].loc[0]:\n",
    "    for key, value in ATTACK_EVENTS_MAP.items():\n",
    "        if value == int(x):\n",
    "            most_common_rep_seq.append(key)\n",
    "            \n",
    "# Generates a fancy table to display\n",
    "dict = {'Most Common Event Sequence': [most_common_seq],\\\n",
    "       'Factor Function': [[0,0,0,0,0,round(common['Number'].loc[0], 3),0,0,0,0,0]],\\\n",
    "       'Attack States':['persistence'],\\\n",
    "       'Probability': [round(common['Number'].loc[0], 3)]}\n",
    "print(\"\\nCOMMONNESS:\")\n",
    "display(pd.DataFrame(dict))\n",
    "\n",
    "dict = {'Most Common Event Sequence': [most_common_rep_seq],\\\n",
    "       'Factor Function': [[0,0,0,0,round(common_rep['Number'].loc[0], 3),0,0,0,0,0,0]],\\\n",
    "       'Attack States':['persistence'],\\\n",
    "       'Probability': [round(common_rep['Number'].loc[0], 3)]}\n",
    "print(\"\\nREPETITIVENESS:\")\n",
    "display(pd.DataFrame(dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2  You will have to submit the graph you draw through Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_sequence_dep = [ 'E' + str(x) for x in [1, 3, 3, 3, 4]]\n",
    "evidence_sequence_dep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DiscreteFactor representing phi(S1:11) at 0x148378dc4c8>, <DiscreteFactor representing phi(S2:11) at 0x14836a51608>, <DiscreteFactor representing phi(S3:11) at 0x148365ab688>, <DiscreteFactor representing phi(S4:11) at 0x14836a51108>, <DiscreteFactor representing phi(S5:11) at 0x14836b70648>, <DiscreteFactor representing phi(S6:11) at 0x148365ab348>, <DiscreteFactor representing phi(S7:11) at 0x14836fbcd48>, <DiscreteFactor representing phi(S8:11) at 0x1483710a848>, <DiscreteFactor representing phi(S9:11) at 0x14836e1eb48>]\n"
     ]
    }
   ],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1', 'E1'], [11,5], f)\n",
    "f_2 = DiscreteFactor(['S2', 'E2'], [11,5], f)\n",
    "f_3 = DiscreteFactor(['S3', 'E3'], [11,5], f)\n",
    "f_4 = DiscreteFactor(['S4', 'E4'], [11,5], f)\n",
    "f_5 = DiscreteFactor(['S5', 'E5'], [11,5], f)\n",
    "f_6 = DiscreteFactor(['S6', 'E6'], [11,5], f)\n",
    "f_7 = DiscreteFactor(['S7', 'E7'], [11,5], f)\n",
    "f_8 = DiscreteFactor(['S8', 'E8'], [11,5], f)\n",
    "f_9 = DiscreteFactor(['S9', 'E9'], [11,5], f)\n",
    "state_margin = [[] for x in range(9)]\n",
    "\n",
    "r_temp = np.zeros([11,5,5,5])\n",
    "r_temp [4,2,2,2] = common_rep['Number'].loc[0]\n",
    "r = DiscreteFactor(['S5', 'E3', 'E4', 'E5'], [11,5,5,5], r_temp)\n",
    "\n",
    "c_temp = np.zeros([11,5,5,5])\n",
    "c_temp [5,0,2,3] = common['Number'].loc[0]\n",
    "c = DiscreteFactor(['S6', 'E1', 'E3' ,'E6'], [11,5,5,5], c_temp) \n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1', 'S3', 'S4', 'S5', 'S6', \\\n",
    "                 'E1', 'E3', 'E4', 'E5', 'E6'])  ## Add random variables \n",
    "G.add_factors(f_1, f_3, f_4, f_5, f_6, r, c)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1', f_1),('S3', f_3),('S4', f_4),('S5', f_5),('S6', f_6),\\\n",
    "                  ('E1', f_1),('E3', f_3),('E4', f_4),('E5', f_5),('E6', f_6),\\\n",
    "                 ('E1', c),('E3', c),('E6', c),('S6', c),\\\n",
    "                 ('E3', r),('E4', r),('E5', r),('S5', r)])\n",
    "\n",
    "###############################\n",
    "#   TODO: Do the inference\n",
    "###############################\n",
    "bp_dep = BeliefPropagation(G)\n",
    "MPS = [[] for x in range(9)] # Most Probable State at time t\n",
    "\n",
    "\n",
    "for i in [1, 3, 4, 5, 6]:\n",
    "    state_margin [i-1] = bp_dep.query(variables = ['S' + str(i)],\\\n",
    "                                      evidence = {'E1': 0, 'E3': 2, 'E4': 2, 'E5': 2, 'E6': 3 }, show_progress = False)\n",
    "                                                                            \n",
    "    state_margin [i-1].normalize()\n",
    "    MPS [i-1] = bp_dep.map_query(variables=['S' + str(i)], evidence = {'E1': 0, 'E3': 2, 'E4': 2, 'E5': 2, 'E6': 3 },\\\n",
    "                                 show_progress = False)\n",
    "\n",
    "'''\n",
    "There are two kinds of graphs: disjoint and joint. PGMPY gives an error if the entire graph is run together. \n",
    "Hence we need to assume the 4 disconnectde nodes are 4 seperate factor graphs and analyze them individually\n",
    "'''\n",
    "\n",
    "f_indep = [f_9, f_8, f_7, f_2]\n",
    "\n",
    "for i in [2,7,8,9]:\n",
    "    factor_current = f_indep.pop()\n",
    "    G_indep = FactorGraph()\n",
    "    G_indep.add_nodes_from(['S' + str(i), 'E' + str(i)])  ## Add random variables \n",
    "    G_indep.add_factors(factor_current)\n",
    "    G_indep.add_edges_from([('S'+str(i), factor_current ),('E'+str(i), factor_current)])\n",
    "    bp_indep = BeliefPropagation(G_indep)\n",
    "    \n",
    "    if i == 2:\n",
    "        value = 1\n",
    "    else: \n",
    "        value = 4\n",
    "    \n",
    "    state_margin [i-1] = bp_indep.query(variables=['S' + str(i)], evidence = {'E'+str(i): value}, show_progress = False)\n",
    "    state_margin [i-1].normalize()\n",
    "    MPS [i-1] = bp_indep.map_query(variables = ['S' + str(i)], evidence = {'E'+str(i): value}, show_progress = False)\n",
    "    \n",
    "print(state_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. At every time point, provide the marginal probability of each state (Since we have 9 time points and 11 possible states, you should provide 99 probability values here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal Probability of S1\n",
      "+--------+-----------+\n",
      "| S1     |   phi(S1) |\n",
      "+========+===========+\n",
      "| S1(0)  |    0.9360 |\n",
      "+--------+-----------+\n",
      "| S1(1)  |    0.0640 |\n",
      "+--------+-----------+\n",
      "| S1(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S1(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S2\n",
      "+--------+-----------+\n",
      "| S2     |   phi(S2) |\n",
      "+========+===========+\n",
      "| S2(0)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| S2(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S2(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S3\n",
      "+--------+-----------+\n",
      "| S3     |   phi(S3) |\n",
      "+========+===========+\n",
      "| S3(0)  |    0.5533 |\n",
      "+--------+-----------+\n",
      "| S3(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(4)  |    0.4467 |\n",
      "+--------+-----------+\n",
      "| S3(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S3(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S4\n",
      "+--------+-----------+\n",
      "| S4     |   phi(S4) |\n",
      "+========+===========+\n",
      "| S4(0)  |    0.5533 |\n",
      "+--------+-----------+\n",
      "| S4(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(4)  |    0.4467 |\n",
      "+--------+-----------+\n",
      "| S4(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S4(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S5\n",
      "+--------+-----------+\n",
      "| S5     |   phi(S5) |\n",
      "+========+===========+\n",
      "| S5(0)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(4)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| S5(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S5(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S6\n",
      "+--------+-----------+\n",
      "| S6     |   phi(S6) |\n",
      "+========+===========+\n",
      "| S6(0)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(5)  |    1.0000 |\n",
      "+--------+-----------+\n",
      "| S6(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(8)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S6(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S7\n",
      "+--------+-----------+\n",
      "| S7     |   phi(S7) |\n",
      "+========+===========+\n",
      "| S7(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| S7(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| S7(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S7(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S8\n",
      "+--------+-----------+\n",
      "| S8     |   phi(S8) |\n",
      "+========+===========+\n",
      "| S8(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| S8(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| S8(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S8(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n",
      "Marginal Probability of S9\n",
      "+--------+-----------+\n",
      "| S9     |   phi(S9) |\n",
      "+========+===========+\n",
      "| S9(0)  |    0.0200 |\n",
      "+--------+-----------+\n",
      "| S9(1)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(2)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(3)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(4)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(5)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(6)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(7)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(8)  |    0.9800 |\n",
      "+--------+-----------+\n",
      "| S9(9)  |    0.0000 |\n",
      "+--------+-----------+\n",
      "| S9(10) |    0.0000 |\n",
      "+--------+-----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Marginal Probability of S\" + str(i+1))\n",
    "    print(state_margin[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. At every time point, provide the most probable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'S1': 0}, {'S2': 0}, {'S3': 0}, {'S4': 0}, {'S5': 4}, {'S6': 5}, {'S7': 8}, {'S8': 8}, {'S9': 8}]\n"
     ]
    }
   ],
   "source": [
    "print(MPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO-OP\n",
      "NO-OP\n",
      "NO-OP\n",
      "NO-OP\n",
      "MONITOR\n",
      "MONITOR\n",
      "STOP\n",
      "STOP\n",
      "STOP\n"
     ]
    }
   ],
   "source": [
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}\n",
    "\n",
    "for i in range(len(MPS)):\n",
    "    stage = MPS[i]['S'+str(i+1)]\n",
    "    prob_value_array = []\n",
    "    for key in ACTIONS.keys():\n",
    "        prob_value_array.append([ACTIONS[key][stage]])\n",
    "    \n",
    "    action = list(ACTIONS)[np.argmax(np.array(prob_value_array))]\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate the earliest stage in which your model should recommend stopping the attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Judge whether the most probable states for $s_1-s_6,s_8,s_9$ remain the same as Task3.2\n",
    "#### b. State the reason for your judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DiscreteFactor representing phi(S1:11) at 0x148367abd48>, <DiscreteFactor representing phi(S2:11) at 0x1483734a608>, <DiscreteFactor representing phi(S3:11) at 0x14836d91ac8>, <DiscreteFactor representing phi(S4:11) at 0x14836a84648>, <DiscreteFactor representing phi(S5:11) at 0x14836572d48>, <DiscreteFactor representing phi(S6:11) at 0x14836b7d148>, [], <DiscreteFactor representing phi(S8:11) at 0x14837a9b108>, <DiscreteFactor representing phi(S9:11) at 0x14836e9fc48>]\n"
     ]
    }
   ],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1', 'E1'], [11,5], f)\n",
    "f_2 = DiscreteFactor(['S2', 'E2'], [11,5], f)\n",
    "f_3 = DiscreteFactor(['S3', 'E3'], [11,5], f)\n",
    "f_4 = DiscreteFactor(['S4', 'E4'], [11,5], f)\n",
    "f_5 = DiscreteFactor(['S5', 'E5'], [11,5], f)\n",
    "f_6 = DiscreteFactor(['S6', 'E6'], [11,5], f)\n",
    "#f_7 = DiscreteFactor(['S7', 'E7'], [11,5], f)\n",
    "f_8 = DiscreteFactor(['S8', 'E8'], [11,5], f)\n",
    "f_9 = DiscreteFactor(['S9', 'E9'], [11,5], f)\n",
    "state_margin = [[] for x in range(9)]\n",
    "\n",
    "r_temp = np.zeros([11,5,5,5])\n",
    "r_temp [4,2,2,2] = common_rep['Number'].loc[0]\n",
    "r = DiscreteFactor(['S5', 'E3', 'E4', 'E5'], [11,5,5,5], r_temp)\n",
    "\n",
    "c_temp = np.zeros([11,5,5,5])\n",
    "c_temp [5,0,2,3] = common['Number'].loc[0]\n",
    "c = DiscreteFactor(['S6', 'E1', 'E3' ,'E6'], [11,5,5,5], c_temp) \n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1', 'S3', 'S4', 'S5', 'S6', \\\n",
    "                 'E1', 'E3', 'E4', 'E5', 'E6'])  ## Add random variables \n",
    "G.add_factors(f_1, f_3, f_4, f_5, f_6, r, c)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1', f_1),('S3', f_3),('S4', f_4),('S5', f_5),('S6', f_6),\\\n",
    "                  ('E1', f_1),('E3', f_3),('E4', f_4),('E5', f_5),('E6', f_6),\\\n",
    "                 ('E1', c),('E3', c),('E6', c),('S6', c),\\\n",
    "                 ('E3', r),('E4', r),('E5', r),('S5', r)])\n",
    "\n",
    "###############################\n",
    "#   TODO: Do the inference\n",
    "###############################\n",
    "bp_dep = BeliefPropagation(G)\n",
    "MPS = [[] for x in range(9)] # Most Probable State at time t\n",
    "\n",
    "\n",
    "for i in [1, 3, 4, 5, 6]:\n",
    "    state_margin [i-1] = bp_dep.query(variables = ['S' + str(i)],\\\n",
    "                        evidence = {'E1': 0, 'E3': 2, 'E4': 2, 'E5': 2, 'E6': 3 }, show_progress = False)\n",
    "    state_margin [i-1].normalize()\n",
    "    MPS [i-1] = bp_dep.map_query(variables=['S' + str(i)], evidence = {'E1': 0, 'E3': 2, 'E4': 2, 'E5': 2, 'E6': 3 },\\\n",
    "                                 show_progress = False)\n",
    "\n",
    "'''\n",
    "There are two kinds of graphs: disjoint and joint. PGMPY gives an error if the entire graph is run together. \n",
    "Hence we need to assume the 4 disconnectde nodes are 4 seperate factor graphs and analyze them individually\n",
    "'''\n",
    "\n",
    "f_indep = [f_9, f_8, f_2]\n",
    "\n",
    "for i in [2,8,9]:\n",
    "    factor_current = f_indep.pop()\n",
    "    G_indep = FactorGraph()\n",
    "    G_indep.add_nodes_from(['S' + str(i), 'E' + str(i)])  ## Add random variables \n",
    "    G_indep.add_factors(factor_current)\n",
    "    G_indep.add_edges_from([('S'+str(i), factor_current ),('E'+str(i), factor_current)])\n",
    "    bp_indep = BeliefPropagation(G_indep)\n",
    "    \n",
    "    if i == 2:\n",
    "        value = 1\n",
    "    else: \n",
    "        value = 4\n",
    "    \n",
    "    state_margin [i-1] = bp_indep.query(variables=['S' + str(i)], evidence = {'E'+str(i): value}, show_progress = False)\n",
    "    state_margin [i-1].normalize()\n",
    "    MPS [i-1] = bp_indep.map_query(variables = ['S' + str(i)], evidence = {'E'+str(i): value}, show_progress = False)\n",
    "    \n",
    "print(state_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'S1': 0}, {'S2': 0}, {'S3': 0}, {'S4': 0}, {'S5': 4}, {'S6': 5}, [], {'S8': 8}, {'S9': 8}]\n",
      "NO-OP\n",
      "NO-OP\n",
      "NO-OP\n",
      "NO-OP\n",
      "MONITOR\n",
      "MONITOR\n",
      "STOP\n",
      "STOP\n"
     ]
    }
   ],
   "source": [
    "print(MPS)\n",
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}\n",
    "\n",
    "for i in range(len(MPS)):\n",
    "    if MPS[i] == []:\n",
    "        continue\n",
    "    stage = MPS[i]['S'+str(i+1)]\n",
    "    prob_value_array = []\n",
    "    for key in ACTIONS.keys():\n",
    "        prob_value_array.append([ACTIONS[key][stage]])\n",
    "    \n",
    "    action = list(ACTIONS)[np.argmax(np.array(prob_value_array))]\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States remain the same. Because an independent node was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Draw an HMM model for the attack scenario given the provided states and events.\n",
    "#### b. What parameters are needed for this HMM model to work?\n",
    "#### c. Give an example of an advantage of the FG over the HMM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Just remove the functions r and c, connect all states by factor functions, and add priors to the states. Everything else remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. State transition probabilities are needed for factor functions between the states and priors are needed for the corresponding factor functions for the states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. HMM is restricted to the Markov assumption that state_t is dependent only on state_t-1. This is not true for this case, as functions r anc c connect different states that are not immediate neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. Not possible to predict wth 100 percent accuracy even if all events were given. This is becasue there is a finite probability of the attack being benign in every stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor Functions common: f_1 to f_8 (connecting events to states) and r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
